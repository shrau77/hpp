import requests, base64, re, os, socket, geoip2.database, json, hashlib, shutil, time, ipaddress
from datetime import datetime
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse, unquote
from concurrent.futures import ThreadPoolExecutor

# ============================================================================
# ‚öôÔ∏è 0. –ü–†–ï–î–í–ê–†–ò–¢–ï–õ–¨–ù–ê–Ø –ù–ê–°–¢–†–û–ô–ö–ê
# ============================================================================

def update_geoip():
    """–ê–≤—Ç–æ-—Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –±–∞–∑—ã GeoIP"""
    db_path = 'GeoLite2-Country.mmdb'
    mirror_url = "https://github.com/P3TERX/GeoLite.mmdb/raw/download/GeoLite2-Country.mmdb"
    
    if not os.path.exists(db_path) or (time.time() - os.path.getmtime(db_path)) > 3 * 86400:
        try:
            print(f"[{datetime.now().strftime('%H:%M:%S')}] üåç Updating GeoIP database...")
            r = requests.get(mirror_url, stream=True, timeout=20)
            if r.status_code == 200:
                with open(db_path, 'wb') as f: shutil.copyfileobj(r.raw, f)
                print("‚úÖ GeoIP database updated.")
        except Exception as e: 
            print(f"‚ö†Ô∏è GeoIP update failed: {e}")

# ============================================================================
# ‚öôÔ∏è 1. –°–ü–ò–°–ö–ò –ò –ö–û–ù–°–¢–ê–ù–¢–´
# ============================================================================

# –ö–∞—Ä—Ç–∞ "–°–≤–æ–∏—Ö" IP (ASN)
RU_ASN_MAP = {
    "51.250.0.0/16": "YANDEX", "84.201.128.0/17": "YANDEX", "158.160.0.0/16": "YANDEX",
    "95.163.0.0/16": "SELECTEL", "87.242.0.0/16": "SELECTEL", 
    "217.16.0.0/16": "MTS-AEZA", "46.17.0.0/16": "FIRSTBYTE",
    "188.93.16.0/20": "AEZA", "77.246.100.0/22": "SERV-PIPE",
    "212.34.138.0/24": "G-CORE"
}

# –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ SNI
TARGET_SNI = list(set([
    # üëë PLATINUM
    "max.ru", "web.max.ru", "download.max.ru", "dev.max.ru", "static.max.ru", "api.max.ru",
    "gosuslugi.ru", "www.mos.ru", "nalog.ru", "esia.gosuslugi.ru",
    "smartcaptcha.yandexcloud.net", "sso.passport.yandex.ru", "api-maps.yandex.ru",
    "video.intfreed.ru", "khabarovsk.geodema.network", "my.oversecure.pro",
    
    # –ò—Å—Ö–æ–¥–Ω—ã–π —Å–ø–∏—Å–æ–∫
    "www.unicreditbank.ru", "www.gazprombank.ru", "cdn.gpb.ru", "mkb.ru", "www.open.ru",
    "cobrowsing.tbank.ru", "cdn.rosbank.ru", "www.psbank.ru", "www.raiffeisen.ru",
    "www.rzd.ru", "st.gismeteo.st", "stat-api.gismeteo.net", "c.dns-shop.ru",
    "restapi.dns-shop.ru", "www.pochta.ru", "passport.pochta.ru", "chat-ct.pochta.ru",
    "www.x5.ru", "www.ivi.ru", "api2.ivi.ru", "hh.ru", "i.hh.ru", "hhcdn.ru",
    "sentry.hh.ru", "cpa.hh.ru", "www.kp.ru", "cdnn21.img.ria.ru", "lenta.ru",
    "sync.rambler.ru", "s.rbk.ru", "www.rbc.ru", "target.smi2.net", "hb-bidder.skcrtxr.com",
    "strm-spbmiran-07.strm.yandex.net", "pikabu.ru", "www.tutu.ru", "cdn1.tu-tu.ru",
    "api.apteka.ru", "static.apteka.ru", "images.apteka.ru", "scitylana.apteka.ru",
    "www.drom.ru", "c.rdrom.ru", "www.farpost.ru", "s11.auto.drom.ru", "i.rdrom.ru",
    "yummy.drom.ru", "www.drive2.ru", "lemanapro.ru", "stats.vk-portal.net",
    "sun6-21.userapi.com", "sun6-20.userapi.com", "avatars.mds.yandex.net",
    "queuev4.vk.com", "sun6-22.userapi.com", "sync.browser.yandex.net", "top-fwz1.mail.ru",
    "ad.mail.ru", "eh.vk.com", "akashi.vk-portal.net", "sun9-38.userapi.com",
    "st.ozone.ru", "ir.ozone.ru", "vt-1.ozone.ru", "io.ozone.ru", "ozone.ru",
    "xapi.ozon.ru", "strm-rad-23.strm.yandex.net", "online.sberbank.ru",
    "esa-res.online.sberbank.ru", "egress.yandex.net", "st.okcdn.ru", "rs.mail.ru",
    "counter.yadro.ru", "742231.ms.ok.ru", "splitter.wb.ru", "a.wb.ru",
    "user-geo-data.wildberries.ru", "banners-website.wildberries.ru",
    "chat-prod.wildberries.ru", "servicepipe.ru", "alfabank.ru", "statad.ru",
    "alfabank.servicecdn.ru", "alfabank.st", "ad.adriver.ru", "privacy-cs.mail.ru",
    "imgproxy.cdn-tinkoff.ru", "mddc.tinkoff.ru", "le.tbank.ru", "hrc.tbank.ru",
    "id.tbank.ru", "rap.skcrtxr.com", "eye.targetads.io", "px.adhigh.net", "nspk.ru",
    "sba.yandex.net", "identitystatic.mts.ru", "tag.a.mts.ru", "login.mts.ru",
    "serving.a.mts.ru", "cm.a.mts.ru", "login.vk.com", "api.a.mts.ru", "mtscdn.ru",
    "d5de4k0ri8jba7ucdbt6.apigw.yandexcloud.net", "moscow.megafon.ru", "api.mindbox.ru",
    "web-static.mindbox.ru", "storage.yandexcloud.net", "personalization-web-stable.mindbox.ru",
    "www.t2.ru", "beeline.api.flocktory.com", "static.beeline.ru", "moskva.beeline.ru",
    "wcm.weborama-tech.ru", "1013a--ma--8935--cp199.stbid.ru", "msk.t2.ru", "s3.t2.ru",
    "get4click.ru", "dzen.ru", "yastatic.net", "csp.yandex.net", "sntr.avito.ru",
    "yabro-wbplugin.edadeal.yandex.ru", "cdn.uxfeedback.ru", "goya.rutube.ru",
    "api.expf.ru", "fb-cdn.premier.one", "www.kinopoisk.ru", "widgets.kinopoisk.ru",
    "payment-widget.plus.kinopoisk.ru", "api.events.plus.yandex.net", "tns-counter.ru",
    "speller.yandex.net", "widgets.cbonds.ru", "www.magnit.com", "magnit-ru.injector.3ebra.net",
    "jsons.injector.3ebra.net", "2gis.ru", "d-assets.2gis.ru", "s1.bss.2gis.com",
    "www.tbank.ru", "strm-spbmiran-08.strm.yandex.net", "id.tbank.ru", "tmsg.tbank.ru",
    "vk.com", "www.wildberries.ru", "www.ozon.ru", "ok.ru", "yandex.ru"
]))

# –°–ø–∏—Å–æ–∫ —á–µ—Ä–Ω—ã—Ö SNI
BLACK_SNI = ['google.com', 'youtube.com', 'facebook.com', 'instagram.com', 'twitter.com', 'porn', 'pusytroller', 'hubp.de', 'dynv6.net']

# –≠–ª–∏—Ç–Ω—ã–µ –ø–æ—Ä—Ç—ã
ELITE_PORTS = ['2053', '2083', '2087', '2096', '8447', '9443', '10443', '8443', '443']
ELITE_PORTS = list(set(ELITE_PORTS))

CHAMPION_HOSTS = ['yandex', 'selectel', 'timeweb', 'firstbyte', 'gcore', 'vkcloud', 'mail.ru']

# –£–õ–¨–¢–†–ê-–≠–õ–ò–¢–ù–´–ï SNI
ULTRA_ELITE_SNI = [
    "hls-svod.itunes.apple.com", "itunes.apple.com", "xp.apple.com",
    "fastsync.xyz", "cloudlane.xyz", "powodzenia.xyz", 
    "shiftline.xyz", "edgeport.xyz", "zoomzoom.xyz", "runstream.xyz", "softpipe.xyz",
    "stats.vk-portal.net", "akashi.vk-portal.net",
    "deepl.com", "www.samsung.com", "cdnjs.cloudflare.com",
    "st.ozone.ru", "disk.yandex.ru", "api.mindbox.ru",
    "travel.yandex.ru", "egress.yandex.net", "sba.yandex.net",
    "strm.yandex.net", "goya.rutube.ru",
    "cdn.tbank.ru", "sso.passport.yandex.ru", "download.max.ru"
]

# –ü–∞—Ç—Ç–µ—Ä–Ω—ã –ø–ª–∞—Ç–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
PREMIUM_PROVIDER_PATTERNS = {
    "iskra": ['connect-iskra.ru', 'iskra-connect.xyz', 'fp=qq', 'xpaddingbytes='],
    "tcp_reset": ['tcp-reset-club.net', 'tcp-reset-club'],
    "abvpn": ['tcpnet.fun', 'tcpdoor.net', 'abvpn.ru', 'fp=firefox'],
    "vezdehod": ['blh', 'rblx', 'gmn']
}

# –ò—Å—Ç–æ—á–Ω–∏–∫–∏ (–ü–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫)
urls = [
    "https://s3c3.001.gpucloud.ru/dggdu/xixz",
    "https://raw.githubusercontent.com/HikaruApps/WhiteLattice/refs/heads/main/subscriptions/config.txt", 
    "https://jsnegsukavsos.hb.ru-msk.vkcloud-storage.ru/love",
    "https://raw.githubusercontent.com/igareck/vpn-configs-for-russia/refs/heads/main/Vless-Reality-White-Lists-Rus-Cable.txt",
    "https://raw.githubusercontent.com/igareck/vpn-configs-for-russia/refs/heads/main/Vless-Reality-White-Lists-Rus-Mobile.txt",
    "https://raw.githubusercontent.com/igareck/vpn-configs-for-russia/refs/heads/main/BLACK_SS%2BAll_RUS.txt",
    "https://raw.githubusercontent.com/STR97/STRUGOV/refs/heads/main/STR.BYPASS", 
    "https://raw.githubusercontent.com/igareck/vpn-configs-for-russia/refs/heads/main/BLACK_VLESS_RUS.txt",
    "https://raw.githubusercontent.com/zieng2/wl/main/vless_lite.txt",
    "https://raw.githubusercontent.com/zieng2/wl/main/vless_universal.txt",
    "https://raw.githubusercontent.com/55prosek-lgtm/vpn_config_for_russia/refs/heads/main/whitelist.txt",
    "https://raw.githubusercontent.com/55prosek-lgtm/vpn_config_for_russia/refs/heads/main/blacklist.txt",
    "https://raw.githubusercontent.com/vlesscollector/vlesscollector/refs/heads/main/vless_configs.txt",
    "https://fsub.flux.2bd.net/githubmirror/bypass/bypass-all.txt",
    "https://etoneya.a9fm.site/1",
    "https://raw.githubusercontent.com/vsevjik/OBSpiskov/refs/heads/main/wwh#OBSpiskov",
    "https://raw.githubusercontent.com/55prosek-lgtm/vpn_config_for_russia/refs/heads/main/blacklist.txt", 
    "https://raw.githubusercontent.com/vlesscollector/vlesscollector/refs/heads/main/vless_configs.txt", 
    "https://fsub.flux.2bd.net/githubmirror/bypass-unsecure/bypass-unsecure-all.txt",
    "https://fsub.flux.2bd.net/githubmirror/split-by-protocols/vmess.txt",
    "https://fsub.flux.2bd.net/githubmirror/split-by-protocols/trojan.txt",
    "https://fsub.flux.2bd.net/githubmirror/split-by-protocols/tuic.txt",
    "https://fsub.flux.2bd.net/githubmirror/split-by-protocols/ssr.txt",
    "https://fsub.flux.2bd.net/githubmirror/split-by-protocols/hysteria.txt",
    "https://fsub.flux.2bd.net/githubmirror/split-by-protocols/hysteria2.txt",
    "https://fsub.flux.2bd.net/githubmirror/split-by-protocols/hy2.txt",
    "http://livpn.atwebpages.com/sub.php?token=c829c20769d2112b", 
    "https://sub-aggregator.vercel.app/",
    "https://s3c3.001.gpucloud.ru/dixsm/htxml",
    "https://shz.al/YjSPQaSTpHYNakFnE2ddjcCK:/~@sorenab1,/VIESS,subSOREN#VIESS,subSOREN", 
    "https://s3c3.001.gpucloud.ru/rtrq/jsoxn", 
    "https://raw.githubusercontent.com/bywarm/whitelists-vpns-etc/refs/heads/main/whitelists1-4pda.txt", 
    *[f"https://raw.githubusercontent.com/AvenCores/goida-vpn-configs/refs/heads/main/githubmirror/{i}.txt" for i in range(1, 27)]
]

class MetaAggregator:
    def __init__(self):
        self.rep_path = 'reputation.json'
        self.reputation = self._load_json(self.rep_path)
        self.geo_cache = {}
        # –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã GeoLite2 –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ main
        self.reader = geoip2.database.Reader('GeoLite2-Country.mmdb') if os.path.exists('GeoLite2-Country.mmdb') else None
        
        self.uuid_counter = {}
        self.sni_counter = {}
    
    def _load_json(self, path):
        if os.path.exists(path):
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    cleaned = {}
                    for k, v in data.items():
                        if isinstance(v, int): 
                            cleaned[k] = {"count": v, "last_seen": int(time.time())}
                        elif isinstance(v, dict):
                            cleaned[k] = v
                    return cleaned
            except: return {}
        return {}
    
    def _check_asn(self, ip):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ ASN"""
        try:
            # FIX: –ï—Å–ª–∏ IP –ø–æ—Ö–æ–∂ –Ω–∞ IP, –ø—Ä–æ–≤–µ—Ä—è–µ–º. –ï—Å–ª–∏ –Ω–µ—Ç - –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º, —á—Ç–æ–±—ã –Ω–µ –∫—Ä–∞—à–∏–ª–æ—Å—å
            if re.match(r'^\d+\.\d+\.\d+\.\d+$', ip):
                ip_obj = ipaddress.ip_address(ip)
                for net, name in RU_ASN_MAP.items():
                    if ip_obj in ipaddress.ip_network(net):
                        return name, "RU"
        except: 
            pass
        return None, None

    def _extract_alpn_decoded(self, node):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏ –¥–µ–∫–æ–¥–∏—Ä—É–µ—Ç ALPN"""
        try:
            patterns = [r'alpn=([^&?\s]+)', r'"alpn":"([^"]+)"', r"'alpn':'([^']+)'"]
            for pattern in patterns:
                match = re.search(pattern, node, re.IGNORECASE)
                if match:
                    alpn_value = match.group(1)
                    try: alpn_value = unquote(alpn_value)
                    except: pass
                    return alpn_value.replace('\\"', '"').replace("\\'", "'")
        except: pass
        return None
    
    def _extract_uuid(self, node):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç UUID (Safe Mode)"""
        try:
            if node.startswith('vmess://'):
                # –î–ª—è VMess –ø—ã—Ç–∞–µ–º—Å—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å, –µ—Å–ª–∏ –Ω–µ –≤—ã—à–ª–æ - –∏—â–µ–º –ø–æ —Ä–µ–≥–µ–∫—Å—É –≤ base64 (—Ä–µ–¥–∫–æ, –Ω–æ –±—ã–≤–∞–µ—Ç)
                try:
                    base_part = node[8:].split('?')[0].split('#')[0]
                    missing = len(base_part) % 4
                    if missing: base_part += '=' * (4 - missing)
                    decoded = base64.b64decode(base_part).decode('utf-8', errors='ignore')
                    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ JSON
                    if '{' in decoded:
                        try:
                            js = json.loads(decoded[decoded.find('{'):decoded.rfind('}')+1])
                            return js.get('id', '')
                        except: pass
                except: pass
            
            # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π Regex –¥–ª—è UUID –≤ —Å—Ç—Ä–æ–∫–µ
            match = re.search(r'[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}', node, re.IGNORECASE)
            if match: return match.group(0)
            
            # –î–ª—è Vless/Trojan –µ—Å–ª–∏ –Ω–µ—Ç UUID (–Ω–∞–ø—Ä–∏–º–µ—Ä, password), –±–µ—Ä–µ–º user part
            if node.startswith(('vless://', 'trojan://')):
                return urlparse(node).netloc.split('@')[0]
                
        except: pass
        return None
    
    def _extract_sni(self, node):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç SNI"""
        try:
            match = re.search(r'sni=([^&?#\s]+)', node.lower())
            if match: return match.group(1).strip('.')
            # –î–ª—è VMess –≤–Ω—É—Ç—Ä–∏ JSON
            if 'vmess://' in node:
                # (–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ –¥–µ–∫–æ–¥–∞ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏, –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∞)
                pass 
        except: pass
        return None
    def _get_uuid_frequency(self, uuid):
        return self.uuid_counter.get(uuid, 0)
    
    def _get_sni_frequency(self, sni):
        return self.sni_counter.get(sni, 0)

    def _update_statistics(self, nodes):
        """–û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É UUID –∏ SNI"""
        try:
            self.uuid_counter.clear()
            self.sni_counter.clear()
            for node in nodes:
                try:
                    uuid = self._extract_uuid(node)
                    if uuid: self.uuid_counter[uuid] = self.uuid_counter.get(uuid, 0) + 1
                    sni = self._extract_sni(node)
                    if sni: self.sni_counter[sni] = self.sni_counter.get(sni, 0) + 1
                except: continue
        except: pass

    def get_node_id(self, node):
        """–•–µ—à –∫–æ–Ω—Ñ–∏–≥–∞ –±–µ–∑ –∏–º–µ–Ω–∏ –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ —Ä–µ–ø—É—Ç–∞—Ü–∏–∏"""
        return hashlib.md5(node.split('#')[0].encode()).hexdigest()

    def get_fp(self, node):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è Fingerprint –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–µ—à–∞ —Å—Å—ã–ª–∫–∏"""
        hash_val = int(self.get_node_id(node), 16)
        choice = hash_val % 100
        if choice < 50: return "chrome"
        if choice < 75: return "ios"
        if choice < 90: return "edge"
        return "safari"

    def calculate_score(self, node):
        score = 0
        n_l = node.lower()
        try:
            parsed = urlparse(node)
        except: return 0
        
        # 1. Reputation (–ò—Å—Ç–æ—Ä–∏—è –∂–∏–∑–Ω–∏ —Å–µ—Ä–≤–µ—Ä–∞)
        node_id = self.get_node_id(node)
        rep_data = self.reputation.get(node_id, {})
        score += rep_data.get('count', 0) * 50

        # 2. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –±–æ–Ω—É—Å—ã
        if 'xtls-rprx-vision' in n_l: score += 300
        if 'type=xhttp' in n_l: score += 400          
        # XUDP –±–æ–ª—å—à–µ –Ω–µ –±–æ–Ω—É—Å–∏—Ç—Å—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ, –Ω–æ –µ—Å–ª–∏ –µ—Å—Ç—å - –Ω–µ —à—Ç—Ä–∞—Ñ—É–µ–º
        if any(p in n_l for p in ['tuic', 'hysteria2', 'hy2']): score += 250
        if 'trojan' in n_l: score += 100
        if 'reality' in n_l or 'security=reality' in n_l: score += 200
        
        # 3. –ü–æ—Ä—Ç—ã
        try:
            port = parsed.netloc.split(':')[-1]
            if port in ELITE_PORTS: score += 250
            elif port == '443': score += 100
        except: pass

        # 4. SNI & Host –∞–Ω–∞–ª–∏–∑
        sni = self._extract_sni(node)
        if sni:
            if 'max.ru' in sni: score += 1000 
            if any(elite_sni in sni for elite_sni in ULTRA_ELITE_SNI): score += 500
            
            if any(s in sni for s in BLACK_SNI): score -= 5000
            if any(ts == sni or sni.endswith('.'+ts) for ts in TARGET_SNI): score += 300
            if "itunes.apple.com" in sni: score += 250
            
            # –ë–æ–Ω—É—Å –∑–∞ —Å—É–±–¥–æ–º–µ–Ω—ã (—á–∞—Å—Ç–æ –ø—Ä–∏–∑–Ω–∞–∫ —á–∏—Å—Ç–æ–≥–æ CDN)
            if (sni.count('.') >= 3 or any(sub in sni for sub in ['st.', 'api.', 'cdn.', 'disk.'])):
                score += 100
        
        # 4.1. ASN Ghost Logic (–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞)
        try:
            host_ip = parsed.netloc.split('@')[-1].split(':')[0]
            asn_name, _ = self._check_asn(host_ip)
            if asn_name: score += 500
        except: pass
        
        if any(h in parsed.netloc for h in CHAMPION_HOSTS): score += 50

        # 5. –ü–ª–∞—Ç–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
        for _, patterns in PREMIUM_PROVIDER_PATTERNS.items():
            if any(marker in n_l for marker in patterns):
                score += 200

        # 6. ALPN & FP
        alpn_value = self._extract_alpn_decoded(node)
        if alpn_value:
            if 'h3' in alpn_value: score += 80
            elif 'h2' in alpn_value: score += 40
            
        if 'fp=' in n_l: score += 50
            
        # 7. –ß–∞—Å—Ç–æ—Ç–∞ UUID (–æ—Ç—Å–µ–∏–≤–∞–µ–º –ø–∞–±–ª–∏–∫ –º—É—Å–æ—Ä)
        uuid = self._extract_uuid(node)
        if uuid:
            uuid_count = self._get_uuid_frequency(uuid)
            # –ï—Å–ª–∏ 1 UUID –Ω–∞ 50 —Å–µ—Ä–≤–µ—Ä–∞—Ö - —ç—Ç–æ –º—É—Å–æ—Ä–Ω—ã–π –ø–∞–±–ª–∏–∫
            if uuid_count >= 50: score -= 100
            elif uuid_count >= 3: score += 50 # –ü–æ–ø—É–ª—è—Ä–Ω—ã–π, –Ω–æ –≤ –º–µ—Ä—É

        return max(score, 0)

    def patch(self, node):
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ü–ê–¢–ß–ï–† (SAFE MODE)
        - –ù–µ –ª–æ–º–∞–µ—Ç VMess
        - –ù–µ —É–¥–∞–ª—è–µ—Ç PBK/SID –¥–ª—è Reality
        - –ù–µ –Ω–∞–≤—è–∑—ã–≤–∞–µ—Ç XUDP
        """
        try:
            # --- VMESS: SKIP PATCHING ---
            # –ò–∑–±–µ–≥–∞–µ–º –ø–µ—Ä–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è Base64, —á—Ç–æ–±—ã –Ω–µ —Ç–µ—Ä—è—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã json
            if node.startswith('vmess://'):
                return node
            
            # --- VLESS / TROJAN ---
            if node.startswith(('vless://', 'trojan://')):
                parsed = urlparse(node)
                # keep_blank_values=True –≤–∞–∂–µ–Ω, —á—Ç–æ–±—ã –Ω–µ —Ç–µ—Ä—è—Ç—å –ø—É—Å—Ç—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
                query = parse_qs(parsed.query, keep_blank_values=True)
                
                changed = False
                
                # 1. Fingerprint (FP) - —Å—Ç–∞–≤–∏–º —Ä–∞–Ω–¥–æ–º–Ω—ã–π, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç
                if 'fp' not in query or not query['fp'][0]:
                    query['fp'] = [self.get_fp(node)]
                    changed = True
                
                # 2. ALPN - —Å—Ç–∞–≤–∏–º –¥–µ—Ñ–æ–ª—Ç, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç
                if 'alpn' not in query or not query['alpn'][0]:
                    query['alpn'] = ['h2,http/1.1']
                    changed = True
                
                # 3. Type fix
                if 'type' in query:
                    net_type = query['type'][0]
                    if net_type == 'ws' and 'path' not in query:
                        query['path'] = ['/']
                        changed = True
                    if net_type == 'grpc' and 'serviceName' not in query:
                        query['serviceName'] = ['grpc']
                        changed = True

                # 4. Reality Fixes (SID check)
                if 'security' in query and query['security'][0] == 'reality':
                    # –ï—Å–ª–∏ –µ—Å—Ç—å pbk, –Ω–æ –Ω–µ—Ç sid -> –¥–æ–±–∞–≤–ª—è–µ–º sid (–∏–Ω–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –¥–ª—è –∫–æ–Ω–Ω–µ–∫—Ç–∞)
                    if 'pbk' in query and 'sid' not in query:
                        query['sid'] = ['1a']
                        changed = True
                    # –í–ê–ñ–ù–û: –ú—ã –±–æ–ª—å—à–µ –Ω–µ —É–¥–∞–ª—è–µ–º –∏ –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã. 
                    # PBK –æ—Å—Ç–∞–Ω–µ—Ç—Å—è –Ω–∞ –º–µ—Å—Ç–µ, —Ç–∞–∫ –∫–∞–∫ parse_qs –µ–≥–æ —Å—á–∏—Ç–∞–ª.

                if changed:
                    new_query = urlencode(query, doseq=True)
                    return urlunparse(parsed._replace(query=new_query))
            
            return node
        except: 
            return node

    def get_geo(self, node):
        """–ì–µ–æ–ª–æ–∫–∞—Ü–∏—è: ASN (Map) ‚Üí IP (GeoLite) ‚Üí Domain Rules"""
        try:
            parsed = urlparse(node)
            if not parsed.netloc: return "UN"
            
            host = parsed.netloc.split('@')[-1].split(':')[0]
            if not host: return "UN"
            
            # 1. Check ASN Map first (–°–≤–æ–∏ –¥–∏–∞–ø–∞–∑–æ–Ω—ã - —Å–∞–º—ã–µ —Ç–æ—á–Ω—ã–µ –¥–ª—è –Ω–∞—Å)
            asn_name, asn_country = self._check_asn(host)
            if asn_country == "RU":
                self.geo_cache[host] = "RU"
                return "RU"

            # Cache check
            if host in self.geo_cache: return self.geo_cache[host]
            
            # 2. GeoLite2 (–µ—Å–ª–∏ —ç—Ç–æ IP)
            if re.match(r'^\d+\.\d+\.\d+\.\d+$', host):
                if self.reader:
                    try:
                        result = self.reader.country(host)
                        country = result.country.iso_code or "UN"
                        self.geo_cache[host] = country
                        return country
                    except: pass
            
            # 3. Domain Rules (–µ—Å–ª–∏ —ç—Ç–æ –¥–æ–º–µ–Ω)
            domain_lower = host.lower()
            if domain_lower.endswith(('.ru', '.su', '.—Ä—Ñ', '.yandex.net', '.mail.ru')):
                self.geo_cache[host] = "RU"
                return "RU"
            if domain_lower.endswith('.kz'): return "KZ"
            if domain_lower.endswith('.by'): return "BY"
            if domain_lower.endswith('.ua'): return "UA"
            if domain_lower.endswith('.tr'): return "TR"
            if domain_lower.endswith('.de'): return "DE"
            if domain_lower.endswith('.us'): return "US"
            
            self.geo_cache[host] = "UN"
            return "UN"
        except: return "UN"

    def generate_server_name(self, geo, index, rep_count, score, node=""):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω–∏"""
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
        if score >= 1500: quality = "PLATINUM"
        elif score >= 1000: quality = "ELITE"
        elif score >= 500: quality = "PREMIUM"
        elif score >= 300: quality = "STANDARD"
        else: quality = "BASIC"
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
        provider = ""
        try:
            parsed = urlparse(node)
            host = parsed.netloc.split('@')[-1].split(':')[0]
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ ASN
            asn_name, _ = self._check_asn(host)
            if asn_name: 
                provider = f"-{asn_name}"
            else:
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ SNI
                sni = self._extract_sni(node)
                if sni:
                    if 'max.ru' in sni: provider = "-VK-MAX"
                    elif 'x5.ru' in sni: provider = "-X5-RETAIL"
                    elif 'tbank' in sni: provider = "-T-BANK"
                    elif 'google' in sni: provider = "-GGL"
        except: pass
        
        flag = "üè≥Ô∏è"
        if geo != "UN" and len(geo) == 2:
            try: flag = "".join(chr(ord(c.upper()) + 127397) for c in geo)
            except: pass
        elif geo == "RU": flag = "üá∑üá∫"
        
        # –§–æ—Ä–º–∞—Ç –±–æ–ª–µ–µ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π, —á—Ç–æ–±—ã –Ω–µ —Ä–µ–∑–∞–ª–æ—Å—å –Ω–∞ –º–æ–±–∏–ª–∫–∞—Ö
        return f"{flag} {geo}{provider}-{index:04d} {quality}"

    def cleanup_reputation(self, max_age_days=30, max_entries=20000):
        now = int(time.time())
        cutoff = now - (max_age_days * 86400)
        clean_db = {k: v for k, v in self.reputation.items() if v.get('last_seen', 0) > cutoff}
        if len(clean_db) > max_entries:
            sorted_rep = sorted(clean_db.items(), key=lambda x: x[1]['count'], reverse=True)
            clean_db = dict(sorted_rep[:max_entries])
        self.reputation = clean_db
        # ============================================================================
# üíæ –§–£–ù–ö–¶–ò–ò –°–û–•–†–ê–ù–ï–ù–ò–Ø –ò MAIN
# ============================================================================

def save(file, data):
    """–§—É–Ω–∫—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ + –≥–µ–Ω–µ—Ä–∞—Ü–∏—è Base64 –≤–µ—Ä—Å–∏–∏"""
    if not data: 
        return
    try:
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏
        content = "\n".join(data)
        with open(file, 'w', encoding='utf-8') as f: 
            f.write(content)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ Base64 –≤–µ—Ä—Å–∏–∏ (–¥–ª—è –º–Ω–æ–≥–∏—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ —ç—Ç–æ –≤–∞–∂–Ω–æ)
        b64_content = base64.b64encode(content.encode('utf-8')).decode('utf-8')
        with open(file + ".b64", 'w', encoding='utf-8') as f:
            f.write(b64_content)
            
        print(f"üíæ {file} (+.b64): {len(data)} –∑–∞–ø–∏—Å–µ–π")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è {file}: {e}")

def main():
    # 1. –û–±–Ω–æ–≤–ª—è–µ–º –±–∞–∑—ã
    update_geoip()
    
    agg = MetaAggregator()
    
    # 2. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    def fetch(url):
        try: 
            # –¢–∞–π–º–∞—É—Ç –ø–æ–º–µ–Ω—å—à–µ, —á—Ç–æ–±—ã –Ω–µ –≤–∏—Å–µ–ª–æ –≤–µ—á–Ω–æ
            return requests.get(url, headers=headers, timeout=10).text
        except Exception:
            return ""
    
    print(f"[{datetime.now().strftime('%H:%M:%S')}] ‚ö° –°–±–æ—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤...")
    with ThreadPoolExecutor(max_workers=20) as ex:
        results = list(ex.map(fetch, urls))
    
    raw_nodes = []
    for content in results:
        if not content: continue
        
        # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –µ—Å–ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤ Base64
        # (–ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –Ω–µ—Ç :// –≤ –Ω–∞—á–∞–ª–µ, —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ —ç—Ç–æ b64)
        if "://" not in content[:100]:
            try: 
                content = base64.b64decode(content).decode('utf-8', errors='ignore')
            except: pass
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º –∏ —á–∏—Å—Ç–∏–º
        nodes = [l.strip() for l in content.splitlines() if l and "://" in l and not l.startswith("//")]
        raw_nodes.extend(nodes)

    print(f"üìä –í—Å–µ–≥–æ —Å—ã—Ä—ã—Ö —Å—Ç—Ä–æ–∫: {len(raw_nodes)}")

    # 3. –ü–µ—Ä–≤–∏—á–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π –∫–ª—é—á –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏, —á—Ç–æ–±—ã –Ω–µ —Ç–µ—Ä—è—Ç—å —Å–µ—Ä–≤–µ—Ä—ã –Ω–∞ –æ–¥–Ω–æ–º IP
    unique_map = {}
    ss_nodes = []
    mobile_nodes = [] 
    
    processed_count = 0
    print(f"[{datetime.now().strftime('%H:%M:%S')}] üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è...")
    
    for node in raw_nodes:
        processed_count += 1
        if processed_count % 5000 == 0:
            print(f"  ...–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count} —Å—Ç—Ä–æ–∫")
            
        if any(trash in node for trash in ["127.0.0.1", "localhost"]):
            continue
            
        try:
            # –£–±–∏—Ä–∞–µ–º –∏–º—è (—Ö–≤–æ—Å—Ç –ø–æ—Å–ª–µ #), —á—Ç–æ–±—ã —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —á–∏—Å—Ç–æ –∫–æ–Ω—Ñ–∏–≥–∏
            base_link = node.split('#')[0]
            
            # --- SS HANDLING ---
            if base_link.startswith('ss://'):
                # –ò—Å–∫–ª—é—á–∞–µ–º VLESS –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥ SS (–ø–ª–∞–≥–∏–Ω—ã)
                if 'v2ray-plugin' in base_link or 'obfs-local' in base_link:
                    pass 
                elif 'vless' in base_link or 'uuid' in base_link:
                    continue 
                
                if base_link not in ss_nodes:
                    ss_nodes.append(node) # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å –∏–º–µ–Ω–µ–º –µ—Å–ª–∏ –µ—Å—Ç—å
                continue
            
            # --- VLESS/VMESS/TROJAN HANDLING ---
            # –ü–∞—Ä—Å–∏–º URL
            try:
                p = urlparse(base_link)
                if not p.netloc: continue
            except: continue

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∫–ª—é—á–∞
            host = p.netloc.split('@')[-1].split(':')[0]
            try: port = p.netloc.split(':')[-1]
            except: port = '443'
            
            uuid = agg._extract_uuid(base_link)
            path = "root"
            
            # –ï—Å–ª–∏ —ç—Ç–æ WS/GRPC, –ø—É—Ç—å —Ç–æ–∂–µ –≤–∞–∂–µ–Ω –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
            # (–æ–¥–∏–Ω —Å–µ—Ä–≤–µ—Ä –º–æ–∂–µ—Ç —Ä–∞–∑–¥–∞–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥–∏ –ø–æ —Ä–∞–∑–Ω—ã–º –ø—É—Ç—è–º)
            query = parse_qs(p.query)
            if 'path' in query: path = query['path'][0]
            elif 'serviceName' in query: path = query['serviceName'][0]
            
            # !!! –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï "–ò–°–ß–ï–ó–ê–Æ–©–ò–•" –°–ï–†–í–ï–†–û–í !!!
            # –ö–ª—é—á —Ç–µ–ø–µ—Ä—å –≤–∫–ª—é—á–∞–µ—Ç PORT, UUID –∏ PATH.
            # –†–∞–Ω—å—à–µ –±—ã–ª —Ç–æ–ª—å–∫–æ host, –ø–æ—ç—Ç–æ–º—É 5 –∫–æ–Ω—Ñ–∏–≥–æ–≤ –Ω–∞ –æ–¥–Ω–æ–º IP —Å—Ö–ª–æ–ø—ã–≤–∞–ª–∏—Å—å –≤ 1.
            uniq_key = f"{host}:{port}:{uuid}:{path}"
            
            # –ú–æ–±–∏–ª—å–Ω—ã–µ –ø–æ–¥–±–æ—Ä–∫–∏
            sni = agg._extract_sni(base_link)
            if sni and any(x in sni for x in ['mts', 'beeline', 'megafon', 't2.ru', 'yota', 'tele2']):
                mobile_nodes.append(base_link)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            if uniq_key not in unique_map:
                unique_map[uniq_key] = base_link
                
        except: 
            continue
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö VLESS/VMESS –Ω–æ–¥
    all_unique_vless = list(unique_map.values())
    
    print(f"‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö VLESS/VMESS/Trojan: {len(all_unique_vless)}")
    print(f"‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö SS: {len(ss_nodes)}")

    # 4. –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (UUID/SNI) –¥–ª—è —Å–∫–æ—Ä–∏–Ω–≥–∞
    agg._update_statistics(all_unique_vless)
    
    # 5. –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ
    print(f"[{datetime.now().strftime('%H:%M:%S')}] üíé –§–∏–Ω–∞–ª—å–Ω—ã–π –ø–∞—Ç—á–∏–Ω–≥ –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ...")
    
    enriched_nodes = []
    for node in all_unique_vless:
        # –ü–∞—Ç—á–∏–º (–±–µ–∑–æ–ø–∞—Å–Ω–æ, —Å–º. –∫–ª–∞—Å—Å MetaAggregator)
        patched_node = agg.patch(node)
        
        # –°—á–∏—Ç–∞–µ–º –æ—á–∫–∏
        final_score = agg.calculate_score(patched_node)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ì–ï–û
        geo = agg.get_geo(patched_node)
        
        enriched_nodes.append({
            'node': patched_node,
            'score': final_score,
            'sni': agg._extract_sni(patched_node),
            'geo': geo,
            'raw': node # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
        }) 
    
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞: –°–Ω–∞—á–∞–ª–∞ –ø–æ –æ—á–∫–∞–º (—É–±—ã–≤–∞–Ω–∏–µ)
    enriched_nodes.sort(key=lambda x: x['score'], reverse=True)
    
    # 6. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–ø–∏—Å–∫–æ–≤
    print(f"[{datetime.now().strftime('%H:%M:%S')}] üìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω –∏ —Å–ø–∏—Å–∫–æ–≤...")
    
    processed_final = []
    now_ts = int(time.time())
    
    # –ë–µ—Ä–µ–º –¢–û–ü-20000 (–∏–ª–∏ —Å–∫–æ–ª—å–∫–æ –Ω—É–∂–Ω–æ)
    TOP_LIMIT = 20000 
    
    for i, item in enumerate(enriched_nodes[:TOP_LIMIT]):
        node = item['node']
        score = item['score']
        geo = item['geo']
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ —Ä–µ–ø—É—Ç–∞—Ü–∏–∏ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—É—Å–∫–∞
        node_id = agg.get_node_id(node)
        rep_entry = agg.reputation.get(node_id, {"count": 0, "last_seen": now_ts})
        rep_entry["count"] += 1
        rep_entry["last_seen"] = now_ts
        agg.reputation[node_id] = rep_entry
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫—Ä–∞—Å–∏–≤–æ–µ –∏–º—è
        name = agg.generate_server_name(str(geo), i+1, rep_entry["count"], score, node)
        
        # –ü—Ä–∏–∫—Ä–µ–ø–ª—è–µ–º –∏–º—è —á–µ—Ä–µ–∑ —Ä–µ—à–µ—Ç–∫—É (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)
        full_link = f"{node}#{name}"
        
        processed_final.append({
            'link': full_link,
            'score': score,
            'sni': item['sni'],
            'node_clean': node
        })
        
    # 7. –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è
    ultra_elite_list = []
    business_list = []
    leaked_gems_list = []
    vless_vmess_list = []
    
    for item in processed_final:
        link = item['link']
        score = item['score']
        node_clean = item['node_clean']
        sni = item['sni']
        
        vless_vmess_list.append(link)
        
        if score >= 1000:
            ultra_elite_list.append(link)
            business_list.append(link)
        elif score >= 500:
            business_list.append(link)
            
        # "Leaked Gems" - —Ä–µ–¥–∫–∏–µ –ø—Ä–æ—Ç–æ–∫–æ–ª—ã –∏–ª–∏ –≤–∞–∂–Ω—ã–µ SNI
        is_xhttp = 'type=xhttp' in node_clean
        is_max = sni and 'max.ru' in sni
        if is_xhttp or is_max:
            leaked_gems_list.append(link)

    # 8. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    print(f"[{datetime.now().strftime('%H:%M:%S')}] üíæ –ó–∞–ø–∏—Å—å —Ñ–∞–π–ª–æ–≤...")

    save("ultra_elite.txt", ultra_elite_list)
    save("business.txt", business_list)
    save("leaked_gems.txt", leaked_gems_list)
    save("ss.txt", ss_nodes) # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ SS
    save("whitelist_mobile.txt", mobile_nodes)
    save("vless_vmess.txt", vless_vmess_list)
    
    # ALL: VLESS + SS
    all_content = vless_vmess_list + ss_nodes
    # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞—Ç—å –Ω–µ –±—É–¥–µ–º, –ø—É—Å—Ç—å VLESS (–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ) –∏–¥—É—Ç –ø–µ—Ä–≤—ã–º–∏
    save("all.txt", all_content)
    
    # Legacy Support (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ —Å—Ç–∞—Ä—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏)
    try:
        shutil.copy("business.txt", "hard_hidden.txt")
        shutil.copy("all.txt", "sub.txt")
        shutil.copy("all.txt", "all_configs.txt")
    except: pass

    # 9. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–∞–∑—ã —Ä–µ–ø—É—Ç–∞—Ü–∏–∏
    agg.cleanup_reputation()
    try:
        with open(agg.rep_path, 'w', encoding='utf-8') as f:
            json.dump(agg.reputation, f, indent=2)
        print("‚úÖ –ë–∞–∑–∞ —Ä–µ–ø—É—Ç–∞—Ü–∏–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∞")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ —Ä–µ–ø—É—Ç–∞—Ü–∏–∏: {e}")

    if agg.reader:
        agg.reader.close()

    print(f"[{datetime.now().strftime('%H:%M:%S')}] üöÄ –ì–æ—Ç–æ–≤–æ.")
    print(f"üìä –ò–¢–û–ì–ò:")
    print(f"  - üíé Ultra Elite: {len(ultra_elite_list)}")
    print(f"  - üíº Business: {len(business_list)}")
    print(f"  - üåê Total (All): {len(all_content)}")

if __name__ == "__main__":
    main() 
